{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:46:55.721248Z",
     "iopub.status.busy": "2025-08-01T00:46:55.721028Z",
     "iopub.status.idle": "2025-08-01T00:48:13.135406Z",
     "shell.execute_reply": "2025-08-01T00:48:13.134539Z",
     "shell.execute_reply.started": "2025-08-01T00:46:55.721231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:48:13.136970Z",
     "iopub.status.busy": "2025-08-01T00:48:13.136660Z",
     "iopub.status.idle": "2025-08-01T00:48:16.668775Z",
     "shell.execute_reply": "2025-08-01T00:48:16.667816Z",
     "shell.execute_reply.started": "2025-08-01T00:48:13.136934Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.7.2)\n",
      "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->captum) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->captum) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->captum) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->captum) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->captum) (2024.2.0)\n",
      "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: captum\n",
      "Successfully installed captum-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-01T00:48:16.671533Z",
     "iopub.status.busy": "2025-08-01T00:48:16.671286Z",
     "iopub.status.idle": "2025-08-01T00:48:40.456220Z",
     "shell.execute_reply": "2025-08-01T00:48:40.455640Z",
     "shell.execute_reply.started": "2025-08-01T00:48:16.671510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 00:48:29.080683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754009309.247326      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754009309.296051      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import string\n",
    "\n",
    "from captum.attr import (\n",
    "    FeatureAblation, \n",
    "    ShapleyValues,\n",
    "    LayerIntegratedGradients, \n",
    "    LLMAttribution, \n",
    "    LLMGradientAttribution, \n",
    "    TextTokenInput, \n",
    "    TextTemplateInput,\n",
    "    ProductBaselines,\n",
    ")\n",
    "\n",
    "# Ignore warnings due to transformers library\n",
    "warnings.filterwarnings(\"ignore\", \".*past_key_values.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*Skipping this token.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:48:41.369854Z",
     "iopub.status.busy": "2025-08-01T00:48:41.369608Z",
     "iopub.status.idle": "2025-08-01T00:48:41.374972Z",
     "shell.execute_reply": "2025-08-01T00:48:41.374218Z",
     "shell.execute_reply.started": "2025-08-01T00:48:41.369837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name, bnb_config):\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "    max_memory = \"10000MB\"\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        num_labels=3,\n",
    "        device_map=\"auto\",  # dispatch efficiently the model on the available ressources\n",
    "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=True)\n",
    "\n",
    "    # Needed for LLaMA tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    return bnb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:48:41.376088Z",
     "iopub.status.busy": "2025-08-01T00:48:41.375799Z",
     "iopub.status.idle": "2025-08-01T00:48:41.608874Z",
     "shell.execute_reply": "2025-08-01T00:48:41.608256Z",
     "shell.execute_reply.started": "2025-08-01T00:48:41.376060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in 'login': write_permission. Will not be supported from version '1.0'.\n",
      "\n",
      "Fine-grained tokens added complexity to the permissions, making it irrelevant to check if a token has 'write' access.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Token has not been saved to git credential helper.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(new_session=False, # Won’t request token if one is already saved on machine\n",
    "write_permission=True, # Requires a token with write permission\n",
    "token=\"\", # The name of your token\n",
    "add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:48:41.609795Z",
     "iopub.status.busy": "2025-08-01T00:48:41.609565Z",
     "iopub.status.idle": "2025-08-01T00:49:00.687526Z",
     "shell.execute_reply": "2025-08-01T00:49:00.686909Z",
     "shell.execute_reply.started": "2025-08-01T00:48:41.609768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8396aa5653fb42d58a46ae32ad257990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/825 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863438507fd4cf39dbe5d2c2943a5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406b13ac326b4b84a3a4206da12e68d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db84a7e4caa8433e80f0f3a72d8066d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2690ad835f41f6bfbebdbff8bb56f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee76b08907e42a380aebf507d464314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8da16735cb74ba18535d3a18c1e7e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"ConditionalNLI/exp8_llama3.2\" \n",
    "bnb_config = create_bnb_config()\n",
    "model, tokenizer = load_model(model_name, bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:00.688786Z",
     "iopub.status.busy": "2025-08-01T00:49:00.688460Z",
     "iopub.status.idle": "2025-08-01T00:49:00.693337Z",
     "shell.execute_reply": "2025-08-01T00:49:00.692676Z",
     "shell.execute_reply.started": "2025-08-01T00:49:00.688759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.problem_type = \"single_label_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:00.696061Z",
     "iopub.status.busy": "2025-08-01T00:49:00.695884Z",
     "iopub.status.idle": "2025-08-01T00:49:03.611784Z",
     "shell.execute_reply": "2025-08-01T00:49:03.611102Z",
     "shell.execute_reply.started": "2025-08-01T00:49:00.696046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Liam is an aerospace engineer, he'll test t...</td>\n",
       "      <td>Liam has a wind tunnel.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wind tunnel</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Bill is a content strategist, he'll manage ...</td>\n",
       "      <td>Bill has a content management application.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his content management application</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Steve is a conservation officer, he'll set ...</td>\n",
       "      <td>Steve has a wildlife trap.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wildlife trap</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Matt is a scuba diver, he'll bring his wets...</td>\n",
       "      <td>Matt has a wetsuit.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wetsuit</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If Noah is a pastry chef, he'll pipe frosting ...</td>\n",
       "      <td>Noah has a pastry bag.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his pastry bag</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>If Christina is a makeup artist, John's friend...</td>\n",
       "      <td>Christina has a makeup sponge.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>John's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>If Rahim is a clergyman, John's friend will ca...</td>\n",
       "      <td>Rahim has a holy book.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>John's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>If James is a police officer, John's friend wi...</td>\n",
       "      <td>James has a gun.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>John's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>If Maya is a piano teachis, John's friend will...</td>\n",
       "      <td>Maya has a metronome.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>John's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>If Aliya is a nurse, John's friend will wear h...</td>\n",
       "      <td>Aliya has scrubs.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>John's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               premise  \\\n",
       "0    If Liam is an aerospace engineer, he'll test t...   \n",
       "1    If Bill is a content strategist, he'll manage ...   \n",
       "2    If Steve is a conservation officer, he'll set ...   \n",
       "3    If Matt is a scuba diver, he'll bring his wets...   \n",
       "4    If Noah is a pastry chef, he'll pipe frosting ...   \n",
       "..                                                 ...   \n",
       "292  If Christina is a makeup artist, John's friend...   \n",
       "293  If Rahim is a clergyman, John's friend will ca...   \n",
       "294  If James is a police officer, John's friend wi...   \n",
       "295  If Maya is a piano teachis, John's friend will...   \n",
       "296  If Aliya is a nurse, John's friend will wear h...   \n",
       "\n",
       "                                     hypothesis gold_label     trigger  \\\n",
       "0                       Liam has a wind tunnel.          E  possessive   \n",
       "1    Bill has a content management application.          E  possessive   \n",
       "2                    Steve has a wildlife trap.          E  possessive   \n",
       "3                           Matt has a wetsuit.          E  possessive   \n",
       "4                        Noah has a pastry bag.          E  possessive   \n",
       "..                                          ...        ...         ...   \n",
       "292              Christina has a makeup sponge.          N  possessive   \n",
       "293                      Rahim has a holy book.          N  possessive   \n",
       "294                            James has a gun.          N  possessive   \n",
       "295                       Maya has a metronome.          N  possessive   \n",
       "296                           Aliya has scrubs.          N  possessive   \n",
       "\n",
       "                             key_phrase       type  \n",
       "0                       his wind tunnel    related  \n",
       "1    his content management application    related  \n",
       "2                     his wildlife trap    related  \n",
       "3                           his wetsuit    related  \n",
       "4                        his pastry bag    related  \n",
       "..                                  ...        ...  \n",
       "292                       John's friend  unrelated  \n",
       "293                       John's friend  unrelated  \n",
       "294                       John's friend  unrelated  \n",
       "295                       John's friend  unrelated  \n",
       "296                       John's friend  unrelated  \n",
       "\n",
       "[297 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df4 = pd.read_excel('/kaggle/input/confer-extension/Part4B_Dataset/4B_Type4.xlsx')\n",
    "test_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:03.612947Z",
     "iopub.status.busy": "2025-08-01T00:49:03.612464Z",
     "iopub.status.idle": "2025-08-01T00:49:03.950966Z",
     "shell.execute_reply": "2025-08-01T00:49:03.948767Z",
     "shell.execute_reply.started": "2025-08-01T00:49:03.612927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Jessica attends the conference, she'll neve...</td>\n",
       "      <td>Jessica has watched a movie by Nolan before.</td>\n",
       "      <td>E</td>\n",
       "      <td>again</td>\n",
       "      <td>watch a movie by Nolan again</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Emily passes her driving test, she'll never...</td>\n",
       "      <td>Emily has read a book by Dan Brown before.</td>\n",
       "      <td>E</td>\n",
       "      <td>again</td>\n",
       "      <td>read a book by Dan Brown again</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Scarlett finishes her work early, she'll ne...</td>\n",
       "      <td>Scarlett has eaten a traditional Swedish dish ...</td>\n",
       "      <td>E</td>\n",
       "      <td>again</td>\n",
       "      <td>eat a traditional Swedish dish again</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Chloe finishes her work early, she'll never...</td>\n",
       "      <td>Chloe has sung a pop song before.</td>\n",
       "      <td>E</td>\n",
       "      <td>again</td>\n",
       "      <td>sing a pop song again</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If Charlotte passes her driving test, she'll n...</td>\n",
       "      <td>Charlotte has listened to a pop song before.</td>\n",
       "      <td>E</td>\n",
       "      <td>again</td>\n",
       "      <td>listen to a pop song again</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>If Dorothy's car breaks down, she'll never obt...</td>\n",
       "      <td>Dorothy has obtained a job position before.</td>\n",
       "      <td>N</td>\n",
       "      <td>again</td>\n",
       "      <td>obtain a job position</td>\n",
       "      <td>no again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>If Susan finishes her work early, she'll never...</td>\n",
       "      <td>Susan has conveyed a confidential message before.</td>\n",
       "      <td>N</td>\n",
       "      <td>again</td>\n",
       "      <td>convey a confidential message</td>\n",
       "      <td>no again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>If Margaret finishes work early, she'll never ...</td>\n",
       "      <td>Margaret has managed to keep a secret before.</td>\n",
       "      <td>N</td>\n",
       "      <td>again</td>\n",
       "      <td>manage to keep a secret</td>\n",
       "      <td>no again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>If Betty misses the bus, she'll never cherish ...</td>\n",
       "      <td>Betty has cherished a moment in peace before.</td>\n",
       "      <td>N</td>\n",
       "      <td>again</td>\n",
       "      <td>cherish a moment in peace</td>\n",
       "      <td>no again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>If Zoey decides to drive, she'll never hold a ...</td>\n",
       "      <td>Zoey has held a student responsible for a mist...</td>\n",
       "      <td>N</td>\n",
       "      <td>again</td>\n",
       "      <td>hold a student responsible for a mistake</td>\n",
       "      <td>no again</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     If Jessica attends the conference, she'll neve...   \n",
       "1     If Emily passes her driving test, she'll never...   \n",
       "2     If Scarlett finishes her work early, she'll ne...   \n",
       "3     If Chloe finishes her work early, she'll never...   \n",
       "4     If Charlotte passes her driving test, she'll n...   \n",
       "...                                                 ...   \n",
       "1595  If Dorothy's car breaks down, she'll never obt...   \n",
       "1596  If Susan finishes her work early, she'll never...   \n",
       "1597  If Margaret finishes work early, she'll never ...   \n",
       "1598  If Betty misses the bus, she'll never cherish ...   \n",
       "1599  If Zoey decides to drive, she'll never hold a ...   \n",
       "\n",
       "                                             hypothesis gold_label trigger  \\\n",
       "0          Jessica has watched a movie by Nolan before.          E   again   \n",
       "1            Emily has read a book by Dan Brown before.          E   again   \n",
       "2     Scarlett has eaten a traditional Swedish dish ...          E   again   \n",
       "3                     Chloe has sung a pop song before.          E   again   \n",
       "4          Charlotte has listened to a pop song before.          E   again   \n",
       "...                                                 ...        ...     ...   \n",
       "1595        Dorothy has obtained a job position before.          N   again   \n",
       "1596  Susan has conveyed a confidential message before.          N   again   \n",
       "1597      Margaret has managed to keep a secret before.          N   again   \n",
       "1598      Betty has cherished a moment in peace before.          N   again   \n",
       "1599  Zoey has held a student responsible for a mist...          N   again   \n",
       "\n",
       "                                    key_phrase      type  \n",
       "0                 watch a movie by Nolan again   related  \n",
       "1               read a book by Dan Brown again   related  \n",
       "2         eat a traditional Swedish dish again   related  \n",
       "3                        sing a pop song again   related  \n",
       "4                   listen to a pop song again   related  \n",
       "...                                        ...       ...  \n",
       "1595                     obtain a job position  no again  \n",
       "1596             convey a confidential message  no again  \n",
       "1597                   manage to keep a secret  no again  \n",
       "1598                 cherish a moment in peace  no again  \n",
       "1599  hold a student responsible for a mistake  no again  \n",
       "\n",
       "[1600 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df5a = pd.read_excel('/kaggle/input/confer-extension/Part4B_Dataset/4B_Type5A.xlsx')\n",
    "test_df5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:03.953662Z",
     "iopub.status.busy": "2025-08-01T00:49:03.953011Z",
     "iopub.status.idle": "2025-08-01T00:49:04.581045Z",
     "shell.execute_reply": "2025-08-01T00:49:04.580313Z",
     "shell.execute_reply.started": "2025-08-01T00:49:03.953600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Jessica attends the conference, her colleag...</td>\n",
       "      <td>Jessica has a colleague.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>her colleague</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Emily passes her driving test, her best fri...</td>\n",
       "      <td>Emily has a best friend.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>her best friend</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Scarlett finishes her work early, her husba...</td>\n",
       "      <td>Scarlett has a husband.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>her husband</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Chloe finishes his work early, his colleagu...</td>\n",
       "      <td>Chloe has colleagues.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his colleagues</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If Charlotte passes her driving test, her pare...</td>\n",
       "      <td>Charlotte has parents.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>her parents</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>If Dorothy car breaks down, Tina's friend will...</td>\n",
       "      <td>Dorothy has a brother.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>Tina's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>If Susan finishes his work early, Tina's frien...</td>\n",
       "      <td>Susan has a colleague.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>Tina's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>If Margaret finishes work early, Tina's friend...</td>\n",
       "      <td>Margaret has a wife.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>Tina's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>If Betty misses the bus, Tina's friend will dr...</td>\n",
       "      <td>Betty has a brother.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>Tina's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>If Zoey decides to drive, Tina's friend will m...</td>\n",
       "      <td>Zoey has friends.</td>\n",
       "      <td>N</td>\n",
       "      <td>possessive</td>\n",
       "      <td>Tina's friend</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                premise  \\\n",
       "0     If Jessica attends the conference, her colleag...   \n",
       "1     If Emily passes her driving test, her best fri...   \n",
       "2     If Scarlett finishes her work early, her husba...   \n",
       "3     If Chloe finishes his work early, his colleagu...   \n",
       "4     If Charlotte passes her driving test, her pare...   \n",
       "...                                                 ...   \n",
       "1195  If Dorothy car breaks down, Tina's friend will...   \n",
       "1196  If Susan finishes his work early, Tina's frien...   \n",
       "1197  If Margaret finishes work early, Tina's friend...   \n",
       "1198  If Betty misses the bus, Tina's friend will dr...   \n",
       "1199  If Zoey decides to drive, Tina's friend will m...   \n",
       "\n",
       "                    hypothesis gold_label     trigger       key_phrase  \\\n",
       "0     Jessica has a colleague.          E  possessive    her colleague   \n",
       "1     Emily has a best friend.          E  possessive  her best friend   \n",
       "2      Scarlett has a husband.          E  possessive      her husband   \n",
       "3        Chloe has colleagues.          E  possessive   his colleagues   \n",
       "4       Charlotte has parents.          E  possessive      her parents   \n",
       "...                        ...        ...         ...              ...   \n",
       "1195    Dorothy has a brother.          N  possessive    Tina's friend   \n",
       "1196    Susan has a colleague.          N  possessive    Tina's friend   \n",
       "1197      Margaret has a wife.          N  possessive    Tina's friend   \n",
       "1198      Betty has a brother.          N  possessive    Tina's friend   \n",
       "1199         Zoey has friends.          N  possessive    Tina's friend   \n",
       "\n",
       "           type  \n",
       "0       related  \n",
       "1       related  \n",
       "2       related  \n",
       "3       related  \n",
       "4       related  \n",
       "...         ...  \n",
       "1195  unrelated  \n",
       "1196  unrelated  \n",
       "1197  unrelated  \n",
       "1198  unrelated  \n",
       "1199  unrelated  \n",
       "\n",
       "[1200 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df5p = pd.read_excel('/kaggle/input/confer-extension/Part4B_Dataset/4B_Type5P.xlsx')\n",
    "test_df5p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:04.582076Z",
     "iopub.status.busy": "2025-08-01T00:49:04.581797Z",
     "iopub.status.idle": "2025-08-01T00:49:05.418922Z",
     "shell.execute_reply": "2025-08-01T00:49:05.417569Z",
     "shell.execute_reply.started": "2025-08-01T00:49:04.582049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Liam is an aerospace engineer, he'll test t...</td>\n",
       "      <td>Liam has a wind tunnel.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wind tunnel</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Bill is a content strategist, he'll manage ...</td>\n",
       "      <td>Bill has a content management application.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his content management application</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Steve is a conservation officer, he'll set ...</td>\n",
       "      <td>Steve has a wildlife trap.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wildlife trap</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Matt is a scuba diver, he'll bring his wets...</td>\n",
       "      <td>Matt has a wetsuit.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wetsuit</td>\n",
       "      <td>related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  If Liam is an aerospace engineer, he'll test t...   \n",
       "1  If Bill is a content strategist, he'll manage ...   \n",
       "2  If Steve is a conservation officer, he'll set ...   \n",
       "3  If Matt is a scuba diver, he'll bring his wets...   \n",
       "\n",
       "                                   hypothesis gold_label     trigger  \\\n",
       "0                     Liam has a wind tunnel.          E  possessive   \n",
       "1  Bill has a content management application.          E  possessive   \n",
       "2                  Steve has a wildlife trap.          E  possessive   \n",
       "3                         Matt has a wetsuit.          E  possessive   \n",
       "\n",
       "                           key_phrase     type  \n",
       "0                     his wind tunnel  related  \n",
       "1  his content management application  related  \n",
       "2                   his wildlife trap  related  \n",
       "3                         his wetsuit  related  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_df = test_df4.iloc[:4].reset_index(drop=True)\n",
    "sample_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:05.420428Z",
     "iopub.status.busy": "2025-08-01T00:49:05.420044Z",
     "iopub.status.idle": "2025-08-01T00:49:06.275068Z",
     "shell.execute_reply": "2025-08-01T00:49:06.274134Z",
     "shell.execute_reply.started": "2025-08-01T00:49:05.420394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_df = sample_test_df\n",
    "test_df = test_df5a\n",
    "possessive_trigger = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:06.276042Z",
     "iopub.status.busy": "2025-08-01T00:49:06.275836Z",
     "iopub.status.idle": "2025-08-01T00:49:07.110337Z",
     "shell.execute_reply": "2025-08-01T00:49:07.109534Z",
     "shell.execute_reply.started": "2025-08-01T00:49:06.276027Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'gold_label', 'trigger', 'key_phrase', 'type'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = Dataset.from_pandas(test_df)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:07.111294Z",
     "iopub.status.busy": "2025-08-01T00:49:07.111023Z",
     "iopub.status.idle": "2025-08-01T00:49:08.049286Z",
     "shell.execute_reply": "2025-08-01T00:49:08.048379Z",
     "shell.execute_reply.started": "2025-08-01T00:49:07.111271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = ['index', 'premise', 'hypothesis']\n",
    "test_ds = test_ds.remove_columns([col for col in test_ds.column_names if col not in columns_to_keep])\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:08.050253Z",
     "iopub.status.busy": "2025-08-01T00:49:08.049947Z",
     "iopub.status.idle": "2025-08-01T00:49:08.808003Z",
     "shell.execute_reply": "2025-08-01T00:49:08.807126Z",
     "shell.execute_reply.started": "2025-08-01T00:49:08.050218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"premise\"], example[\"hypothesis\"], truncation=True, max_length=256, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:08.809451Z",
     "iopub.status.busy": "2025-08-01T00:49:08.808938Z",
     "iopub.status.idle": "2025-08-01T00:49:09.941855Z",
     "shell.execute_reply": "2025-08-01T00:49:09.941177Z",
     "shell.execute_reply.started": "2025-08-01T00:49:08.809425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6e86e702e14103b8ace1eafb32725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "tokenized_test_ds.set_format(\"torch\")\n",
    "tokenized_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:09.942713Z",
     "iopub.status.busy": "2025-08-01T00:49:09.942504Z",
     "iopub.status.idle": "2025-08-01T00:49:10.059915Z",
     "shell.execute_reply": "2025-08-01T00:49:10.059292Z",
     "shell.execute_reply.started": "2025-08-01T00:49:09.942698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_ds = tokenized_test_ds.remove_columns([\"premise\", \"hypothesis\"])\n",
    "tokenized_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:10.060901Z",
     "iopub.status.busy": "2025-08-01T00:49:10.060606Z",
     "iopub.status.idle": "2025-08-01T00:49:10.908989Z",
     "shell.execute_reply": "2025-08-01T00:49:10.908201Z",
     "shell.execute_reply.started": "2025-08-01T00:49:10.060879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predicting Labels on Dataset\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n",
    "dataloader = DataLoader(tokenized_test_ds, batch_size=32, collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "test_df['predicted_label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:10.910132Z",
     "iopub.status.busy": "2025-08-01T00:49:10.909851Z",
     "iopub.status.idle": "2025-08-01T00:49:10.923803Z",
     "shell.execute_reply": "2025-08-01T00:49:10.923209Z",
     "shell.execute_reply.started": "2025-08-01T00:49:10.910108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>expected_logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Liam is an aerospace engineer, he'll test t...</td>\n",
       "      <td>Liam has a wind tunnel.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wind tunnel</td>\n",
       "      <td>related</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Bill is a content strategist, he'll manage ...</td>\n",
       "      <td>Bill has a content management application.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his content management application</td>\n",
       "      <td>related</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Steve is a conservation officer, he'll set ...</td>\n",
       "      <td>Steve has a wildlife trap.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wildlife trap</td>\n",
       "      <td>related</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Matt is a scuba diver, he'll bring his wets...</td>\n",
       "      <td>Matt has a wetsuit.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wetsuit</td>\n",
       "      <td>related</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  If Liam is an aerospace engineer, he'll test t...   \n",
       "1  If Bill is a content strategist, he'll manage ...   \n",
       "2  If Steve is a conservation officer, he'll set ...   \n",
       "3  If Matt is a scuba diver, he'll bring his wets...   \n",
       "\n",
       "                                   hypothesis gold_label     trigger  \\\n",
       "0                     Liam has a wind tunnel.          E  possessive   \n",
       "1  Bill has a content management application.          E  possessive   \n",
       "2                  Steve has a wildlife trap.          E  possessive   \n",
       "3                         Matt has a wetsuit.          E  possessive   \n",
       "\n",
       "                           key_phrase     type  predicted_label  \\\n",
       "0                     his wind tunnel  related                2   \n",
       "1  his content management application  related                2   \n",
       "2                   his wildlife trap  related                2   \n",
       "3                         his wetsuit  related                2   \n",
       "\n",
       "  expected_logits  \n",
       "0       [0, 0, 1]  \n",
       "1       [0, 0, 1]  \n",
       "2       [0, 0, 1]  \n",
       "3       [0, 0, 1]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['expected_logits'] = test_df['gold_label'].map({'C':[1,0,0],'N':[0,1,0],'E':[0,0,1]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:10.924836Z",
     "iopub.status.busy": "2025-08-01T00:49:10.924590Z",
     "iopub.status.idle": "2025-08-01T00:49:10.936936Z",
     "shell.execute_reply": "2025-08-01T00:49:10.936346Z",
     "shell.execute_reply.started": "2025-08-01T00:49:10.924820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogitWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output.logits\n",
    "        logits = logits.unsqueeze(0) # add third dimension \n",
    "        output.logits = logits\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:10.938113Z",
     "iopub.status.busy": "2025-08-01T00:49:10.937841Z",
     "iopub.status.idle": "2025-08-01T00:49:10.950804Z",
     "shell.execute_reply": "2025-08-01T00:49:10.950159Z",
     "shell.execute_reply.started": "2025-08-01T00:49:10.938089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wrapped_model = LogitWrapper(model)\n",
    "lig = LayerIntegratedGradients(wrapped_model, model.model.embed_tokens)\n",
    "llm_attr = LLMGradientAttribution(lig, tokenizer)\n",
    "skip_tokens = ['<|begin_of_text|>','<|end_of_text|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:49:10.951754Z",
     "iopub.status.busy": "2025-08-01T00:49:10.951452Z",
     "iopub.status.idle": "2025-08-01T00:49:10.965128Z",
     "shell.execute_reply": "2025-08-01T00:49:10.964391Z",
     "shell.execute_reply.started": "2025-08-01T00:49:10.951737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_attrs(row):\n",
    "\n",
    "    premise = row['premise']\n",
    "    hypothesis = row['hypothesis']\n",
    "    target = torch.tensor(row['expected_logits'])    \n",
    "    \n",
    "    inp = TextTokenInput(\n",
    "        premise + tokenizer.eos_token + hypothesis,\n",
    "        tokenizer,\n",
    "        skip_tokens=skip_tokens,\n",
    "    )\n",
    "    attr_res = llm_attr.attribute(inp, target=target, skip_tokens=skip_tokens)\n",
    "    result = {\n",
    "        'tokens': attr_res.input_tokens,\n",
    "        'attrs': attr_res.seq_attr\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T01:44:57.141103Z",
     "iopub.status.busy": "2025-08-01T01:44:57.140542Z",
     "iopub.status.idle": "2025-08-01T01:44:57.147560Z",
     "shell.execute_reply": "2025-08-01T01:44:57.146958Z",
     "shell.execute_reply.started": "2025-08-01T01:44:57.141083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reformat_output(result):\n",
    "\n",
    "    i = 0 # position counter\n",
    "    token_gradients = defaultdict(float)\n",
    "    print(result['tokens'])\n",
    "    for token, grad in zip(result['tokens'], result['attrs']):\n",
    "        if token.startswith('▁'):\n",
    "            token = token[1:]\n",
    "        \n",
    "        token_gradients[(token,i)] += grad.item()\n",
    "        i += 1 \n",
    "\n",
    "    token_gradients = dict(token_gradients)\n",
    "    tokens = [tok[0] for tok in list(token_gradients.keys())]\n",
    "    word_gradients = {}\n",
    "    print(token_gradients.keys())\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        word = tokens[i]\n",
    "        if word.startswith('Ġ'):\n",
    "            word = word[1:]\n",
    "        count = 1 \n",
    "        word_gradient = token_gradients[(token,i)]\n",
    "        if word in ['[SEP]','[CLS]']:\n",
    "             word_gradients[(word,i)] = word_gradient\n",
    "             continue # do not merge with next token\n",
    "        while (i+1)<len(tokens) and tokens[i+1] not in string.punctuation and not tokens[i+1].startswith('Ġ') and not tokens[i+1] == '[SEP]':\n",
    "            # part of same word, add gradients together and then average out \n",
    "            i += 1 # move to next word\n",
    "            word += tokens[i] # concatente to restore word \n",
    "            word_gradient += token_gradients[(tokens[i],i)]\n",
    "            count += 1\n",
    "        # end of word \n",
    "        word_gradients[(word,i)] = word_gradient/count # averaging\n",
    "    \n",
    "    return word_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:51:56.491273Z",
     "iopub.status.busy": "2025-08-01T00:51:56.491024Z",
     "iopub.status.idle": "2025-08-01T00:51:56.495011Z",
     "shell.execute_reply": "2025-08-01T00:51:56.494320Z",
     "shell.execute_reply.started": "2025-08-01T00:51:56.491257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_average_gradient(result):\n",
    "     # average gradient per token\n",
    "    return float(sum(result['attrs'])/len(result['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:59:46.780839Z",
     "iopub.status.busy": "2025-08-01T00:59:46.780294Z",
     "iopub.status.idle": "2025-08-01T00:59:46.786380Z",
     "shell.execute_reply": "2025-08-01T00:59:46.785669Z",
     "shell.execute_reply.started": "2025-08-01T00:59:46.780813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_trigger_gradients(row):\n",
    "    \n",
    "    gradients = 0\n",
    "    count = 0\n",
    "    trigger_words = []\n",
    "\n",
    "    # split phrases into individual words\n",
    "    trigger_words = row['key_phrase'].split()\n",
    "\n",
    "    # get gradient of all words in this example\n",
    "    word_gradients = row['word_gradients']\n",
    "    word_gradients_words = [key[0] for key in list(word_gradients.keys())] # extracting word portion of keys\n",
    "    \n",
    "    word_index_mapping = {}\n",
    "    \n",
    "    for word, index in list(word_gradients.keys()):\n",
    "        word_index_mapping.setdefault(word,index) # set the first value (premise value) as the index\n",
    "    \n",
    "    for word in trigger_words:\n",
    "        if word in word_gradients_words:\n",
    "            word_index = word_index_mapping[word]\n",
    "            gradients += word_gradients[(word,word_index)]\n",
    "            count += 1 \n",
    "        elif word.lower() in word_gradients_words:\n",
    "            word_index = word_index_mapping[word.lower()]\n",
    "            gradients += word_gradients[(word.lower(),word_index)]\n",
    "            count += 1 \n",
    "        else:\n",
    "            print(f\"{row.name}: {word} not found!\")\n",
    "\n",
    "    # compute avg gradient of trigger tokens\n",
    "    return gradients/count if count > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T00:52:02.961436Z",
     "iopub.status.busy": "2025-08-01T00:52:02.961168Z",
     "iopub.status.idle": "2025-08-01T00:52:02.968471Z",
     "shell.execute_reply": "2025-08-01T00:52:02.967691Z",
     "shell.execute_reply.started": "2025-08-01T00:52:02.961416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_trigger_word_ranking(word_gradients,possessive_trigger):\n",
    "\n",
    "    sorted_dict = dict(sorted(word_gradients.items(), key=lambda item: item[1],reverse=True))\n",
    "    sorted_dict = {k: v for k,v in sorted_dict.items() if k[0] not in ['[CLS]','[SEP]'] and k[0] not in string.punctuation}\n",
    "    word_gradients_df = pd.DataFrame.from_dict(sorted_dict, orient='index', columns=['Gradient'])\n",
    "    word_gradients_df['Ranking'] = range(1, len(word_gradients_df) + 1)\n",
    "    word_gradients_df['Percentile Ranking'] = word_gradients_df['Ranking'].apply(lambda x: x / len(word_gradients_df))\n",
    "\n",
    "    word_gradients_words = [key[0] for key in list(word_gradients.keys())] # extracting word portion of keys \n",
    "\n",
    "    if possessive_trigger:\n",
    "        if 'his' in word_gradients_words:\n",
    "            key_trigger_word = 'his'\n",
    "        elif 'her' in word_gradients_words:\n",
    "            key_trigger_word = 'her'\n",
    "        elif 'their' in word_gradients_words:\n",
    "            key_trigger_word = 'their'\n",
    "    else:\n",
    "        key_trigger_word = 'again'\n",
    "\n",
    "    try:\n",
    "        key_trigger_word_rank = word_gradients_df.loc[key_trigger_word]['Ranking']\n",
    "        key_trigger_word_percent_rank = word_gradients_df.loc[key_trigger_word]['Percentile Ranking']\n",
    "    except:\n",
    "        key_trigger_word_rank = None \n",
    "        key_trigger_word_percent_rank = None\n",
    "        print(f\"Trigger word not found! - {key_trigger_word}\")\n",
    "\n",
    "    return pd.Series([key_trigger_word_rank, key_trigger_word_percent_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-01T01:45:07.347218Z",
     "iopub.status.busy": "2025-08-01T01:45:07.346977Z",
     "iopub.status.idle": "2025-08-01T01:45:24.979786Z",
     "shell.execute_reply": "2025-08-01T01:45:24.979075Z",
     "shell.execute_reply.started": "2025-08-01T01:45:07.347202Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/captum/attr/_core/llm_attr.py:840: UserWarning: Pretty tokens length 0 != ids length 3! Falling back to naive decoding logic.\n",
      "  _convert_ids_to_pretty_tokens(target_tokens, self.tokenizer),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'ĠLiam', 'Ġis', 'Ġan', 'Ġaerospace', 'Ġengineer', ',', 'Ġhe', \"'ll\", 'Ġtest', 'Ġthe', 'Ġdesigns', 'Ġin', 'Ġhis', 'Ġwind', 'Ġtunnel', '.', 'L', 'iam', 'Ġhas', 'Ġa', 'Ġwind', 'Ġtunnel', '.']\n",
      "dict_keys([('If', 0), ('ĠLiam', 1), ('Ġis', 2), ('Ġan', 3), ('Ġaerospace', 4), ('Ġengineer', 5), (',', 6), ('Ġhe', 7), (\"'ll\", 8), ('Ġtest', 9), ('Ġthe', 10), ('Ġdesigns', 11), ('Ġin', 12), ('Ġhis', 13), ('Ġwind', 14), ('Ġtunnel', 15), ('.', 16), ('L', 17), ('iam', 18), ('Ġhas', 19), ('Ġa', 20), ('Ġwind', 21), ('Ġtunnel', 22), ('.', 23)])\n",
      "['If', 'ĠBill', 'Ġis', 'Ġa', 'Ġcontent', 'Ġstrategist', ',', 'Ġhe', \"'ll\", 'Ġmanage', 'Ġeverything', 'Ġin', 'Ġhis', 'Ġcontent', 'Ġmanagement', 'Ġapplication', '.', 'Bill', 'Ġhas', 'Ġa', 'Ġcontent', 'Ġmanagement', 'Ġapplication', '.']\n",
      "dict_keys([('If', 0), ('ĠBill', 1), ('Ġis', 2), ('Ġa', 3), ('Ġcontent', 4), ('Ġstrategist', 5), (',', 6), ('Ġhe', 7), (\"'ll\", 8), ('Ġmanage', 9), ('Ġeverything', 10), ('Ġin', 11), ('Ġhis', 12), ('Ġcontent', 13), ('Ġmanagement', 14), ('Ġapplication', 15), ('.', 16), ('Bill', 17), ('Ġhas', 18), ('Ġa', 19), ('Ġcontent', 20), ('Ġmanagement', 21), ('Ġapplication', 22), ('.', 23)])\n",
      "['If', 'ĠSteve', 'Ġis', 'Ġa', 'Ġconservation', 'Ġofficer', ',', 'Ġhe', \"'ll\", 'Ġset', 'Ġup', 'Ġhis', 'Ġwildlife', 'Ġtrap', 'Ġto', 'Ġcapture', 'Ġanimals', 'Ġfor', 'Ġresearch', 'Ġor', 'Ġrelocation', '.', 'Steve', 'Ġhas', 'Ġa', 'Ġwildlife', 'Ġtrap', '.']\n",
      "dict_keys([('If', 0), ('ĠSteve', 1), ('Ġis', 2), ('Ġa', 3), ('Ġconservation', 4), ('Ġofficer', 5), (',', 6), ('Ġhe', 7), (\"'ll\", 8), ('Ġset', 9), ('Ġup', 10), ('Ġhis', 11), ('Ġwildlife', 12), ('Ġtrap', 13), ('Ġto', 14), ('Ġcapture', 15), ('Ġanimals', 16), ('Ġfor', 17), ('Ġresearch', 18), ('Ġor', 19), ('Ġrelocation', 20), ('.', 21), ('Steve', 22), ('Ġhas', 23), ('Ġa', 24), ('Ġwildlife', 25), ('Ġtrap', 26), ('.', 27)])\n",
      "['If', 'ĠMatt', 'Ġis', 'Ġa', 'Ġsc', 'uba', 'Ġdiver', ',', 'Ġhe', \"'ll\", 'Ġbring', 'Ġhis', 'Ġw', 'ets', 'uit', '.', 'Matt', 'Ġhas', 'Ġa', 'Ġw', 'ets', 'uit', '.']\n",
      "dict_keys([('If', 0), ('ĠMatt', 1), ('Ġis', 2), ('Ġa', 3), ('Ġsc', 4), ('uba', 5), ('Ġdiver', 6), (',', 7), ('Ġhe', 8), (\"'ll\", 9), ('Ġbring', 10), ('Ġhis', 11), ('Ġw', 12), ('ets', 13), ('uit', 14), ('.', 15), ('Matt', 16), ('Ġhas', 17), ('Ġa', 18), ('Ġw', 19), ('ets', 20), ('uit', 21), ('.', 22)])\n",
      "Trigger word not found! - again\n",
      "Trigger word not found! - again\n",
      "Trigger word not found! - again\n",
      "Trigger word not found! - again\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>trigger</th>\n",
       "      <th>key_phrase</th>\n",
       "      <th>type</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>expected_logits</th>\n",
       "      <th>attr_result</th>\n",
       "      <th>word_gradients</th>\n",
       "      <th>average_gradient</th>\n",
       "      <th>trigger_gradient</th>\n",
       "      <th>trigger_word_ranking</th>\n",
       "      <th>trigger_word_percentile_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Liam is an aerospace engineer, he'll test t...</td>\n",
       "      <td>Liam has a wind tunnel.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wind tunnel</td>\n",
       "      <td>related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>{'tokens': ['If', 'ĠLiam', 'Ġis', 'Ġan', 'Ġaer...</td>\n",
       "      <td>{('If', 0): 1.275778777198866e-05, ('Liam', 1)...</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If Bill is a content strategist, he'll manage ...</td>\n",
       "      <td>Bill has a content management application.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his content management application</td>\n",
       "      <td>related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>{'tokens': ['If', 'ĠBill', 'Ġis', 'Ġa', 'Ġcont...</td>\n",
       "      <td>{('If', 0): 0.0002884181449189782, ('Bill', 1)...</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If Steve is a conservation officer, he'll set ...</td>\n",
       "      <td>Steve has a wildlife trap.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wildlife trap</td>\n",
       "      <td>related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>{'tokens': ['If', 'ĠSteve', 'Ġis', 'Ġa', 'Ġcon...</td>\n",
       "      <td>{('If', 0): 0.0006778022507205606, ('Steve', 1...</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Matt is a scuba diver, he'll bring his wets...</td>\n",
       "      <td>Matt has a wetsuit.</td>\n",
       "      <td>E</td>\n",
       "      <td>possessive</td>\n",
       "      <td>his wetsuit</td>\n",
       "      <td>related</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>{'tokens': ['If', 'ĠMatt', 'Ġis', 'Ġa', 'Ġsc',...</td>\n",
       "      <td>{('If', 0): 0.00021063859458081424, ('Matt', 1...</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  If Liam is an aerospace engineer, he'll test t...   \n",
       "1  If Bill is a content strategist, he'll manage ...   \n",
       "2  If Steve is a conservation officer, he'll set ...   \n",
       "3  If Matt is a scuba diver, he'll bring his wets...   \n",
       "\n",
       "                                   hypothesis gold_label     trigger  \\\n",
       "0                     Liam has a wind tunnel.          E  possessive   \n",
       "1  Bill has a content management application.          E  possessive   \n",
       "2                  Steve has a wildlife trap.          E  possessive   \n",
       "3                         Matt has a wetsuit.          E  possessive   \n",
       "\n",
       "                           key_phrase     type predicted_label  \\\n",
       "0                     his wind tunnel  related             NaN   \n",
       "1  his content management application  related             NaN   \n",
       "2                   his wildlife trap  related             NaN   \n",
       "3                         his wetsuit  related             NaN   \n",
       "\n",
       "  expected_logits                                        attr_result  \\\n",
       "0       [0, 0, 1]  {'tokens': ['If', 'ĠLiam', 'Ġis', 'Ġan', 'Ġaer...   \n",
       "1       [0, 0, 1]  {'tokens': ['If', 'ĠBill', 'Ġis', 'Ġa', 'Ġcont...   \n",
       "2       [0, 0, 1]  {'tokens': ['If', 'ĠSteve', 'Ġis', 'Ġa', 'Ġcon...   \n",
       "3       [0, 0, 1]  {'tokens': ['If', 'ĠMatt', 'Ġis', 'Ġa', 'Ġsc',...   \n",
       "\n",
       "                                      word_gradients  average_gradient  \\\n",
       "0  {('If', 0): 1.275778777198866e-05, ('Liam', 1)...          0.001006   \n",
       "1  {('If', 0): 0.0002884181449189782, ('Bill', 1)...         -0.000913   \n",
       "2  {('If', 0): 0.0006778022507205606, ('Steve', 1...          0.000426   \n",
       "3  {('If', 0): 0.00021063859458081424, ('Matt', 1...          0.000823   \n",
       "\n",
       "   trigger_gradient trigger_word_ranking trigger_word_percentile_ranking  \n",
       "0          0.000751                 None                            None  \n",
       "1          0.000465                 None                            None  \n",
       "2          0.000509                 None                            None  \n",
       "3         -0.000349                 None                            None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['attr_result'] = test_df.apply(compute_attrs, axis=1)\n",
    "test_df.to_csv('part4b_type5a_llama_raw.csv')\n",
    "test_df['word_gradients'] = test_df['attr_result'].apply(reformat_output)\n",
    "test_df['average_gradient'] = test_df['attr_result'].apply(get_average_gradient)\n",
    "test_df['trigger_gradient'] = test_df.apply(compute_trigger_gradients,axis=1)\n",
    "test_df['predicted_label'] = test_df['predicted_label'].map({0:'C',1:'N',2:'E'})\n",
    "test_df[['trigger_word_ranking','trigger_word_percentile_ranking']] = test_df['word_gradients'].apply(compute_trigger_word_ranking,args=(possessive_trigger,))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('part4b_type5a_llama_results_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6568489,
     "sourceId": 12019260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7663069,
     "sourceId": 12315798,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
